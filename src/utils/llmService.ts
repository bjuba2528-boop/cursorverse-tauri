// LLM —Å–µ—Ä–≤–∏—Å –Ω–∞ –±–∞–∑–µ Google Gemini
import { invoke } from '@tauri-apps/api/core'

// –¢–∏–ø—ã –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
export type LLMProvider = 'gemini' | 'yandexgpt' | 'lmstudio' | 'lucy'

// –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
export interface LLMConfig {
  provider: LLMProvider
  apiKey?: string
  baseURL?: string
  model?: string
  temperature?: number
  maxTokens?: number
  catalogId?: string // –î–ª—è YandexGPT (ID –∫–∞—Ç–∞–ª–æ–≥–∞ Yandex Cloud)
}

// –°–æ–æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç–µ
export interface ChatMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

// –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
export interface ActionResult {
  success: boolean
  output: string
  error?: string
}

// –î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–≥–µ–Ω—Ç–∞
export interface Tool {
  name: string
  description: string
  parameters: Record<string, any>
  execute: (params: any) => Promise<ActionResult>
}

class UniversalLLMService {
  private config: LLMConfig = {
    provider: 'lmstudio', // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é LM Studio (–ª–æ–∫–∞–ª—å–Ω–∞—è LLaMA)
    model: 'lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF',
    temperature: 0.7,
    maxTokens: 2000,
    apiKey: 'lm-studio', // LM Studio –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∫–ª—é—á–∞
    catalogId: '', // Folder ID –∏–∑ Yandex Cloud
    baseURL: 'http://localhost:1234/v1'
  }

  private isConnected: boolean = false
  private conversationHistory: ChatMessage[] = []
  private availableTools: Map<string, Tool> = new Map()

  constructor() {
    this.initTools()
    this.loadConfig()
    this.init()
  }

  // –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ localStorage
  private loadConfig() {
    try {
      const saved = localStorage.getItem('llm_config')
      if (saved) {
        const parsed = JSON.parse(saved)
        this.config = { 
          ...this.config, 
          ...parsed
        }
        console.log('üìù –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:', this.config.provider, this.config.model)
      }
    } catch (e: any) {
      console.error('–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:', e)
    }
  }

  // –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
  saveConfig(config: Partial<LLMConfig>) {
    this.config = { ...this.config, ...config }
    localStorage.setItem('llm_config', JSON.stringify(this.config))
    console.log('üíæ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞:', this.config.provider)
    this.init()
  }

  // –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
  getConfig(): LLMConfig {
    return { ...this.config }
  }

  // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
  async init() {
    try {
      const provider = this.config.provider || 'yandexgpt'
      console.log(`üîå –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ${provider}...`)
      
      if (provider === 'gemini') {
        this.isConnected = !!(this.config.apiKey && this.config.apiKey.trim().length > 0)
        console.log('‚úÖ Gemini –≥–æ—Ç–æ–≤ (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π API –∫–ª—é—á)')
      } else if (provider === 'yandexgpt') {
        this.isConnected = !!(this.config.apiKey && this.config.apiKey.trim().length > 0 && 
                             this.config.catalogId && this.config.catalogId.trim().length > 0)
        if (this.isConnected) {
          console.log('‚úÖ YandexGPT –≥–æ—Ç–æ–≤')
        } else {
          console.warn('‚ö†Ô∏è –£–∫–∞–∂–∏—Ç–µ API –∫–ª—é—á –∏ Catalog ID –¥–ª—è YandexGPT')
        }
      } else if (provider === 'lmstudio') {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LM Studio
        try {
          const response = await fetch(`${this.config.baseURL}/models`, { signal: AbortSignal.timeout(3000) })
          this.isConnected = response.ok
          if (this.isConnected) {
            console.log('‚úÖ LM Studio –≥–æ—Ç–æ–≤ (–ª–æ–∫–∞–ª—å–Ω–∞—è LLaMA)')
          } else {
            console.warn('‚ö†Ô∏è LM Studio –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:1234')
          }
        } catch (error) {
          this.isConnected = false
          console.warn('‚ö†Ô∏è LM Studio –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ LM Studio –∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å.')
        }
      }
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏:', error)
      this.isConnected = false
    }
  }

  // –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
  isReady(): boolean {
    return this.isConnected
  }

  // –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –≤ LLM —á–µ—Ä–µ–∑ REST API
  async chat(messages: ChatMessage[]): Promise<string> {
    if (!this.isReady()) {
      throw new Error('AI –Ω–µ –≥–æ—Ç–æ–≤. –£–∫–∞–∂–∏—Ç–µ API –∫–ª—é—á –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö.')
    }

    try {
      const provider = this.config.provider || 'yandexgpt'
      
      switch (provider) {
        case 'gemini':
          return await this.chatGemini(messages)
        case 'yandexgpt':
          return await this.chatYandexGPT(messages)
        case 'lmstudio':
          return await this.chatLMStudio(messages)
        case 'lucy':
          return await this.chatLucy(messages)
        default:
          throw new Error(`–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: ${provider}`)
      }
    } catch (error: any) {
      console.error('‚ùå –û—à–∏–±–∫–∞ LLM:', error)
      throw error
    }
  }

  // Google Gemini API
  private async chatGemini(messages: ChatMessage[]): Promise<string> {
    const apiKey = this.config.apiKey as string
    const model = this.config.model || 'gemini-2.0-flash-exp'

    console.log('ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –≤ Gemini 2.0...')
    console.log('üìã –ú–æ–¥–µ–ª—å:', model)
    
    // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç Gemini
    const geminiContents = []
    let systemInstruction = ''
    
    for (const msg of messages) {
      if (msg.role === 'system') {
        systemInstruction = msg.content
      } else {
        geminiContents.push({
          role: msg.role === 'user' ? 'user' : 'model',
          parts: [{ text: msg.content }]
        })
      }
    }

    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), 30000) // 30 —Å–µ–∫—É–Ω–¥

    try {
      const requestBody: any = {
        contents: geminiContents,
        generationConfig: {
          temperature: this.config.temperature ?? 0.7,
          maxOutputTokens: this.config.maxTokens ?? 2000,
          topP: 0.95,
          topK: 40
        }
      }

      // –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
      if (systemInstruction) {
        requestBody.systemInstruction = {
          parts: [{ text: systemInstruction }]
        }
      }

      const response = await fetch(
        `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`,
        {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify(requestBody),
          signal: controller.signal
        }
      )

      if (!response.ok) {
        const errorText = await response.text()
        console.error('‚ùå Gemini error:', errorText)
        throw new Error(`Gemini API error: ${response.status} - ${errorText}`)
      }

      const data = await response.json()
      console.log('‚úÖ Gemini response received')
      
      const text = data.candidates?.[0]?.content?.parts?.[0]?.text
        
      if (!text) throw new Error('–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini')
      return text.trim()
    } catch (error: any) {
      if (error.name === 'AbortError') {
        throw new Error('–ó–∞–ø—Ä–æ—Å –∫ Gemini –æ—Ç–º–µ–Ω—ë–Ω –ø–æ —Ç–∞–π–º–∞—É—Ç—É.')
      }
      console.error('‚ùå Gemini error:', error)
      throw error
    } finally {
      clearTimeout(timeoutId)
    }
  }

  // LM Studio API (OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π)
  private async chatLMStudio(messages: ChatMessage[]): Promise<string> {
    const baseURL = this.config.baseURL || 'http://localhost:1234/v1'

    const openaiMessages = messages.map(m => ({
      role: m.role === 'system' ? 'system' : m.role === 'user' ? 'user' : 'assistant',
      content: m.content
    }))

    console.log('ü¶ô –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –≤ LM Studio (LLaMA)...')
    
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), 60000) // 60 —Å–µ–∫—É–Ω–¥ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏

    try {
      const response = await fetch(`${baseURL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: this.config.model || 'lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF',
          messages: openaiMessages,
          temperature: this.config.temperature ?? 0.7,
          max_tokens: this.config.maxTokens ?? 2000,
          stream: false
        }),
        signal: controller.signal
      })

      if (!response.ok) {
        const errorText = await response.text()
        throw new Error(`LM Studio API error: ${response.status} - ${errorText}`)
      }

      const data = await response.json()
      const text = data.choices?.[0]?.message?.content
      
      if (!text) throw new Error('–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LM Studio')
      return text.trim()
    } catch (error: any) {
      if (error.name === 'AbortError') {
        throw new Error('–ó–∞–ø—Ä–æ—Å –∫ LM Studio –æ—Ç–º–µ–Ω—ë–Ω –ø–æ —Ç–∞–π–º–∞—É—Ç—É.')
      }
      throw error
    } finally {
      clearTimeout(timeoutId)
    }
  }

  // YandexGPT API
  private async chatYandexGPT(messages: ChatMessage[]): Promise<string> {
    const apiKey = this.config.apiKey as string
    const catalogId = this.config.catalogId || ''
    const model = this.config.model || 'yandexgpt-lite'
    const baseURL = this.config.baseURL || 'https://llm.api.cloud.yandex.net/foundationModels/v1'

    const yandexMessages = messages.map(m => ({
      role: m.role === 'system' ? 'system' : m.role === 'user' ? 'user' : 'assistant',
      text: m.content
    }))

    console.log('ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –≤ YandexGPT...')
    
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), 25000) // 25 —Å–µ–∫—É–Ω–¥

    try {
      const response = await fetch(`${baseURL}/completion`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Api-Key ${apiKey}`,
          'x-folder-id': catalogId
        },
        body: JSON.stringify({
          modelUri: `gpt://${catalogId}/${model}/latest`,
          completionOptions: {
            temperature: this.config.temperature ?? 0.7,
            maxTokens: this.config.maxTokens ?? 2000
          },
          messages: yandexMessages
        }),
        signal: controller.signal
      })

      if (!response.ok) {
        const errorText = await response.text()
        throw new Error(`YandexGPT API error: ${response.status} - ${errorText}`)
      }

      const data = await response.json()
      const text = data.result?.alternatives?.[0]?.message?.text
      
      if (!text) throw new Error('–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç YandexGPT')
      return text.trim()
    } catch (error: any) {
      if (error.name === 'AbortError') {
        throw new Error('–ó–∞–ø—Ä–æ—Å –∫ YandexGPT –æ—Ç–º–µ–Ω—ë–Ω –ø–æ —Ç–∞–π–º–∞—É—Ç—É.')
      }
      throw error
    } finally {
      clearTimeout(timeoutId)
    }
  }

  // Lucy AI (GitHub Models) - –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ –æ—Ç GitHub
  private async chatLucy(messages: ChatMessage[]): Promise<string> {
    const token = this.config.apiKey as string
    const model = this.config.model || 'gpt-4o'
    const baseURL = this.config.baseURL || 'https://models.inference.ai.azure.com'

    console.log('üîå –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ lucy...')
    console.log('Model:', model)
    console.log('Token:', token ? `${token.substring(0, 20)}...` : 'NOT SET')
    console.log('BaseURL:', baseURL)

    try {
      const response = await fetch(`${baseURL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${token}`
        },
        body: JSON.stringify({
          model,
          messages: messages.map(msg => ({
            role: msg.role,
            content: msg.content
          })),
          temperature: this.config.temperature || 0.7,
          max_tokens: this.config.maxTokens || 2000
        })
      })

      if (!response.ok) {
        const errorText = await response.text()
        throw new Error(`Lucy AI error: ${response.status} - ${errorText}`)
      }

      const data = await response.json()
      const text = data.choices?.[0]?.message?.content

      if (!text) throw new Error('–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Lucy AI')
      return text.trim()
    } catch (error: any) {
      console.error('‚ùå –û—à–∏–±–∫–∞ Lucy AI:', error)
      throw error
    }
  }

  // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
  private initTools() {
    // –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ shell –∫–æ–º–∞–Ω–¥—ã
    this.availableTools.set('execute_command', {
      name: 'execute_command',
      description: '–í—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–º–∞–Ω–¥—É –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ (cmd, powershell)',
      parameters: {
        command: 'string',
        args: 'array'
      },
      execute: async (params) => {
        try {
          const result = await invoke('execute_shell_command', {
            command: params.command,
            args: params.args || []
          })
          return { success: true, output: String(result) }
        } catch (error) {
          return { success: false, output: '', error: String(error) }
        }
      }
    })

    // –û—Ç–∫—Ä—ã—Ç–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    this.availableTools.set('open_application', {
      name: 'open_application',
      description: '–û—Ç–∫—Ä—ã—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
      parameters: {
        appName: 'string'
      },
      execute: async (params) => {
        try {
          await invoke('open_application', { appName: params.appName })
          return { success: true, output: `–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ ${params.appName} –æ—Ç–∫—Ä—ã—Ç–æ` }
        } catch (error) {
          return { success: false, output: '', error: String(error) }
        }
      }
    })

    // –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    this.availableTools.set('create_file', {
      name: 'create_file',
      description: '–°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª',
      parameters: {
        path: 'string',
        content: 'string'
      },
      execute: async (params) => {
        try {
          await invoke('create_file', {
            path: params.path,
            content: params.content || ''
          })
          return { success: true, output: `–§–∞–π–ª —Å–æ–∑–¥–∞–Ω: ${params.path}` }
        } catch (error) {
          return { success: false, output: '', error: String(error) }
        }
      }
    })

    // –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
    this.availableTools.set('read_file', {
      name: 'read_file',
      description: '–ü—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª',
      parameters: {
        path: 'string'
      },
      execute: async (params) => {
        try {
          const result = await invoke('read_file', { path: params.path })
          return { success: true, output: String(result) }
        } catch (error) {
          return { success: false, output: '', error: String(error) }
        }
      }
    })

    // –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
    this.availableTools.set('get_processes', {
      name: 'get_processes',
      description: '–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤',
      parameters: {},
      execute: async () => {
        try {
          const result = await invoke('get_process_list')
          return { success: true, output: String(result) }
        } catch (error) {
          return { success: false, output: '', error: String(error) }
        }
      }
    })

    // –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ
    this.availableTools.set('get_system_info', {
      name: 'get_system_info',
      description: '–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ',
      parameters: {},
      execute: async () => {
        try {
          const result = await invoke('get_system_info')
          return { success: true, output: String(result) }
        } catch (error) {
          return { success: false, output: '', error: String(error) }
        }
      }
    })

    // –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
    this.availableTools.set('search_web', {
      name: 'search_web',
      description: '–ò—Å–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ —á–µ—Ä–µ–∑ DuckDuckGo',
      parameters: {
        query: 'string'
      },
      execute: async (params) => {
        try {
          const result = await invoke('search_web', { query: params.query })
          return { success: true, output: String(result) }
        } catch (error) {
          return { success: false, output: '', error: String(error) }
        }
      }
    })

    console.log(`üõ†Ô∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ ${this.availableTools.size} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤`)
  }

  // –ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
  async autonomousThink(userRequest: string, maxIterations: number = 5): Promise<string> {
    if (!this.isReady()) {
      throw new Error('llm –Ω–µ –≥–æ—Ç–æ–≤')
    }

    console.log('üß† –ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ...')
    console.log('üìù –ó–∞–ø—Ä–æ—Å:', userRequest)

    this.conversationHistory = []

    // –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    const systemPrompt = `–¢—ã - –õ—é—Å–∏, –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π AI-–∞–≥–µ–Ω—Ç —Å –ø–æ–ª–Ω—ã–º –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–º–ø—å—é—Ç–µ—Ä—É.

–ò–ù–°–¢–†–£–ú–ï–ù–¢–´:
${Array.from(this.availableTools.entries())
  .map(([name, tool]) => `- ${name}: ${tool.description}`)
  .join('\n')}

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞:
TOOL: <–Ω–∞–∑–≤–∞–Ω–∏–µ>
PARAMS: <JSON –ø–∞—Ä–∞–º–µ—Ç—Ä—ã>
REASON: <–ø—Ä–∏—á–∏–Ω–∞>

–ö–æ–≥–¥–∞ –≥–æ—Ç–æ–≤–æ:
DONE: <—Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç>

–ü–†–ê–í–ò–õ–ê:
1. –î—É–º–∞–π –ª–æ–≥–∏—á–µ—Å–∫–∏, –ø–ª–∞–Ω–∏—Ä—É–π –¥–µ–π—Å—Ç–≤–∏—è
2. –ú–æ–∂–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–µ–π—Å—Ç–≤–∏–π
3. –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–π –æ–± –æ–ø–∞—Å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏—è—Ö
4. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º`

    this.conversationHistory.push({
      role: 'system',
      content: systemPrompt
    })

    this.conversationHistory.push({
      role: 'user',
      content: userRequest
    })

    let iteration = 0
    let finalAnswer = ''
    const executionLog: string[] = []

    while (iteration < maxIterations) {
      iteration++
      console.log(`üîÑ –ò—Ç–µ—Ä–∞—Ü–∏—è ${iteration}/${maxIterations}`)

      const agentResponse = await this.chat(this.conversationHistory)
      console.log('ü§ñ –û—Ç–≤–µ—Ç:', agentResponse)

      if (agentResponse.includes('DONE:')) {
        const match = agentResponse.match(/DONE:\s*(.+)/s)
        if (match) {
          finalAnswer = match[1].trim()
          break
        }
      }

      if (agentResponse.includes('TOOL:')) {
        const toolMatch = agentResponse.match(/TOOL:\s*(\w+)/i)
        const paramsMatch = agentResponse.match(/PARAMS:\s*(\{[\s\S]*?\})/i)
        const reasonMatch = agentResponse.match(/REASON:\s*(.+)/i)

        if (toolMatch && paramsMatch) {
          const toolName = toolMatch[1]
          const tool = this.availableTools.get(toolName)

          if (tool) {
            try {
              const params = JSON.parse(paramsMatch[1])
              const reason = reasonMatch ? reasonMatch[1].trim() : '–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ'

              console.log(`üõ†Ô∏è –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: ${toolName}`)
              console.log('üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:', params)

              executionLog.push(reason)

              const result = await tool.execute(params)

              if (result.success) {
                console.log('‚úÖ', result.output)
                executionLog.push(`‚úÖ ${result.output}`)

                this.conversationHistory.push({
                  role: 'assistant',
                  content: agentResponse
                })

                this.conversationHistory.push({
                  role: 'user',
                  content: `–†–µ–∑—É–ª—å—Ç–∞—Ç ${toolName}: ${result.output}\n\n–ß—Ç–æ –¥–∞–ª—å—à–µ? –ï—Å–ª–∏ –≥–æ—Ç–æ–≤–æ - –æ—Ç–≤–µ—Ç—å DONE:`
                })
              } else {
                console.log('‚ùå', result.error)
                executionLog.push(`‚ùå ${result.error}`)

                this.conversationHistory.push({
                  role: 'assistant',
                  content: agentResponse
                })

                this.conversationHistory.push({
                  role: 'user',
                  content: `–û—à–∏–±–∫–∞ ${toolName}: ${result.error}\n\n–ü–æ–ø—Ä–æ–±—É–π –∏–Ω–∞—á–µ –∏–ª–∏ –æ—Ç–≤–µ—Ç—å DONE:`
                })
              }
            } catch (error: any) {
              console.error('‚ùå –û—à–∏–±–∫–∞:', error)
              this.conversationHistory.push({
                role: 'user',
                content: `–û—à–∏–±–∫–∞: ${error}. –û—Ç–≤–µ—Ç—å DONE:`
              })
            }
          }
        }
      } else {
        this.conversationHistory.push({
          role: 'assistant',
          content: agentResponse
        })

        this.conversationHistory.push({
          role: 'user',
          content: '–ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏–ª–∏ –æ—Ç–≤–µ—Ç—å DONE:'
        })
      }
    }

    if (!finalAnswer) {
      finalAnswer = `‚ö†Ô∏è –ù–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ ${maxIterations} –∏—Ç–µ—Ä–∞—Ü–∏–π.\n\n${executionLog.join('\n')}`
    } else if (executionLog.length > 0) {
      finalAnswer = `${executionLog.join('\n')}\n\n${finalAnswer}`
    }

    console.log('üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç:', finalAnswer)
    return finalAnswer
  }

  // –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
  getAvailableTools(): string[] {
    return Array.from(this.availableTools.keys())
  }

  // –ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è
  async reconnect() {
    this.isConnected = false
    await this.init()
  }
}

// –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
export const llmService = new UniversalLLMService()
